{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Level Prediction for Pakistani Cities\n",
    "\n",
    "This notebook demonstrates the complete pipeline for predicting air quality levels in Pakistani cities using machine learning.\n",
    "\n",
    "## Objectives\n",
    "- Predict daily AQI category (Good, Moderate, Unhealthy, etc.)\n",
    "- Forecast 3 days ahead\n",
    "- Handle time-series data with environmental features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data processing module\n",
    "from data_processing import AirQualityDataProcessor\n",
    "\n",
    "# Initialize processor\n",
    "processor = AirQualityDataProcessor()\n",
    "\n",
    "# Create and process data\n",
    "print(\"Creating sample air quality data...\")\n",
    "df_raw = processor.create_sample_data()\n",
    "\n",
    "print(\"\\nRaw data shape:\", df_raw.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "df_clean = processor.clean_data(df_raw)\n",
    "\n",
    "print(\"Cleaned data shape:\", df_clean.shape)\n",
    "print(\"\\nData info:\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n",
    "print(f\"Cities: {list(df_clean['City'].unique())}\")\n",
    "print(f\"Total records: {len(df_clean)}\")\n",
    "\n",
    "print(\"\\nAQI Statistics by City:\")\n",
    "df_clean.groupby('City')['AQI'].agg(['mean', 'std', 'min', 'max']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AQI Category Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Overall distribution\n",
    "df_clean['AQI_Category'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Overall AQI Category Distribution')\n",
    "axes[0].set_xlabel('AQI Category')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# By city\n",
    "city_aqi = pd.crosstab(df_clean['City'], df_clean['AQI_Category'])\n",
    "city_aqi.plot(kind='bar', stacked=True, ax=axes[1])\n",
    "axes[1].set_title('AQI Category Distribution by City')\n",
    "axes[1].set_xlabel('City')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# AQI trends by city\n",
    "for city in df_clean['City'].unique():\n",
    "    city_data = df_clean[df_clean['City'] == city]\n",
    "    monthly_avg = city_data.groupby(city_data['Date'].dt.to_period('M'))['AQI'].mean()\n",
    "    axes[0, 0].plot(monthly_avg.index.astype(str), monthly_avg.values, marker='o', label=city)\n",
    "\n",
    "axes[0, 0].set_title('Monthly Average AQI Trends by City')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Average AQI')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Seasonal patterns\n",
    "seasonal_aqi = df_clean.groupby('Month')['AQI'].mean()\n",
    "axes[0, 1].plot(seasonal_aqi.index, seasonal_aqi.values, marker='o', color='red')\n",
    "axes[0, 1].set_title('Seasonal AQI Pattern (Average by Month)')\n",
    "axes[0, 1].set_xlabel('Month')\n",
    "axes[0, 1].set_ylabel('Average AQI')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Weekly patterns\n",
    "weekly_aqi = df_clean.groupby('DayOfWeek')['AQI'].mean()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1, 0].bar(day_names, weekly_aqi.values, color='skyblue')\n",
    "axes[1, 0].set_title('Weekly AQI Pattern (Average by Day of Week)')\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Average AQI')\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_cols = ['AQI', 'PM2.5', 'PM10', 'O3', 'NO2', 'SO2', 'CO', 'Temperature', 'Humidity', 'Wind_Speed', 'Pressure']\n",
    "corr_matrix = df_clean[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather vs AQI analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Temperature vs AQI\n",
    "axes[0, 0].scatter(df_clean['Temperature'], df_clean['AQI'], alpha=0.5)\n",
    "axes[0, 0].set_xlabel('Temperature (¬∞C)')\n",
    "axes[0, 0].set_ylabel('AQI')\n",
    "axes[0, 0].set_title('Temperature vs AQI')\n",
    "\n",
    "# Humidity vs AQI\n",
    "axes[0, 1].scatter(df_clean['Humidity'], df_clean['AQI'], alpha=0.5, color='orange')\n",
    "axes[0, 1].set_xlabel('Humidity (%)')\n",
    "axes[0, 1].set_ylabel('AQI')\n",
    "axes[0, 1].set_title('Humidity vs AQI')\n",
    "\n",
    "# Wind Speed vs AQI\n",
    "axes[1, 0].scatter(df_clean['Wind_Speed'], df_clean['AQI'], alpha=0.5, color='green')\n",
    "axes[1, 0].set_xlabel('Wind Speed (km/h)')\n",
    "axes[1, 0].set_ylabel('AQI')\n",
    "axes[1, 0].set_title('Wind Speed vs AQI')\n",
    "\n",
    "# Pressure vs AQI\n",
    "axes[1, 1].scatter(df_clean['Pressure'], df_clean['AQI'], alpha=0.5, color='red')\n",
    "axes[1, 1].set_xlabel('Pressure (hPa)')\n",
    "axes[1, 1].set_ylabel('AQI')\n",
    "axes[1, 1].set_title('Pressure vs AQI')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature engineering module\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "# Initialize feature engineer\n",
    "fe = FeatureEngineer()\n",
    "\n",
    "# Create features\n",
    "print(\"Creating features...\")\n",
    "df_features = fe.prepare_features(df_clean)\n",
    "\n",
    "print(f\"\\nOriginal features: {df_clean.shape[1]}\")\n",
    "print(f\"Engineered features: {df_features.shape[1]}\")\n",
    "print(f\"New features created: {df_features.shape[1] - df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature types\n",
    "feature_types = {\n",
    "    'Lag Features': [col for col in df_features.columns if 'lag' in col],\n",
    "    'Rolling Features': [col for col in df_features.columns if 'roll' in col],\n",
    "    'Seasonal Features': [col for col in df_features.columns if any(x in col for x in ['sin', 'cos', 'Season', 'Weekend'])],\n",
    "    'Interaction Features': [col for col in df_features.columns if any(x in col for x in ['Temp_Humidity', 'Wind_Pressure', 'PM_Ratio'])],\n",
    "    'Target Features': [col for col in df_features.columns if 'target' in col]\n",
    "}\n",
    "\n",
    "for feature_type, features in feature_types.items():\n",
    "    print(f\"\\n{feature_type} ({len(features)}):\")\n",
    "    for feature in features[:5]:  # Show first 5\n",
    "        print(f\"  - {feature}\")\n",
    "    if len(features) > 5:\n",
    "        print(f\"  ... and {len(features) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X_train, X_test, y_train, y_test, test_df = fe.get_model_data(df_features)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Target distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model training module\n",
    "from model_training import AQIPredictor\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = AQIPredictor()\n",
    "predictor.feature_engineer = fe\n",
    "\n",
    "# Train models\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model, rf_predictions = predictor.train_random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model, xgb_predictions = predictor.train_xgboost(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for model_name, performance in predictor.model_performance.items():\n",
    "    print(f\"{model_name:15} - Accuracy: {performance['accuracy']:.4f}, F1-Score: {performance['f1_score']:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_model, best_model_name = predictor.select_best_model()\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': fe.feature_columns,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'{best_model_name} - Top 20 Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:30} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_file = predictor.save_model(best_model, best_model_name, fe)\n",
    "print(f\"Model saved to: {model_file}\")\n",
    "\n",
    "# Create prediction outputs\n",
    "best_predictions = predictor.model_performance[best_model_name]['predictions']\n",
    "prediction_output = predictor.create_predictions_output(test_df, best_predictions, best_model_name)\n",
    "\n",
    "print(f\"\\nPrediction output shape: {prediction_output.shape}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "prediction_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast visualization\n",
    "from prediction import AQIForecastor\n",
    "\n",
    "# Load the saved model\n",
    "forecaster = AQIForecastor(model_file)\n",
    "\n",
    "# Generate forecasts for all cities\n",
    "cities = df_clean['City'].unique()\n",
    "latest_date = df_clean['Date'].max()\n",
    "\n",
    "print(f\"Generating 3-day forecasts from {latest_date.date()}...\")\n",
    "\n",
    "all_forecasts = []\n",
    "for city in cities:\n",
    "    try:\n",
    "        forecasts = forecaster.forecast_multiple_days(df_clean, city, latest_date, days=3)\n",
    "        all_forecasts.extend(forecasts)\n",
    "        \n",
    "        print(f\"\\n{city} Forecast:\")\n",
    "        for forecast in forecasts:\n",
    "            print(f\"  {forecast['Date'].date()}: {forecast['Predicted_AQI_Category']} (Confidence: {forecast['Confidence']:.2f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error forecasting for {city}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate alerts\n",
    "alerts = forecaster.generate_alerts(all_forecasts)\n",
    "\n",
    "print(f\"\\nAIR QUALITY ALERTS ({len(alerts)} alerts):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if alerts:\n",
    "    for alert in alerts:\n",
    "        print(f\"üö® {alert['Alert_Level']} ALERT: {alert['City']} - {alert['Date'].date()}\")\n",
    "        print(f\"   Category: {alert['Predicted_Category']} (Confidence: {alert['Confidence']:.2f})\")\n",
    "        print(f\"   {alert['Message']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚úÖ No air quality alerts for the forecast period.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City risk ranking\n",
    "risk_ranking = forecaster.get_city_risk_ranking(df_clean, cities, latest_date)\n",
    "\n",
    "print(f\"\\nCITY RISK RANKING for {latest_date.date()}:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, city_risk in enumerate(risk_ranking, 1):\n",
    "    risk_level = \"üî¥ HIGH\" if city_risk['Risk_Score'] > 3 else \"üü° MEDIUM\" if city_risk['Risk_Score'] > 2 else \"üü¢ LOW\"\n",
    "    print(f\"{i:2d}. {city_risk['City']:12} - {city_risk['Predicted_Category']:25} {risk_level} (Score: {city_risk['Risk_Score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 80)\n",
    "print(\"AIR QUALITY PREDICTION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä DATASET INFORMATION:\")\n",
    "print(f\"   ‚Ä¢ Cities: {', '.join(cities)}\")\n",
    "print(f\"   ‚Ä¢ Date Range: {df_clean['Date'].min().date()} to {df_clean['Date'].max().date()}\")\n",
    "print(f\"   ‚Ä¢ Total Records: {len(df_clean):,}\")\n",
    "print(f\"   ‚Ä¢ Features Created: {len(fe.feature_columns)}\")\n",
    "\n",
    "print(f\"\\nü§ñ MODEL PERFORMANCE:\")\n",
    "for model_name, performance in predictor.model_performance.items():\n",
    "    print(f\"   ‚Ä¢ {model_name:15}: Accuracy = {performance['accuracy']:.3f}, F1-Score = {performance['f1_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {predictor.model_performance[best_model_name]['accuracy']:.3f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {predictor.model_performance[best_model_name]['f1_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"   ‚Ä¢ Model: {model_file}\")\n",
    "print(f\"   ‚Ä¢ Predictions: outputs/aqi_predictions_{best_model_name}.csv\")\n",
    "print(f\"   ‚Ä¢ Confusion Matrix: outputs/{best_model_name.lower()}_confusion_matrix.png\")\n",
    "print(f\"   ‚Ä¢ Feature Importance: outputs/{best_model_name.lower()}_feature_importance.png\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  ALERTS GENERATED: {len(alerts)}\")\n",
    "if alerts:\n",
    "    alert_cities = list(set([alert['City'] for alert in alerts]))\n",
    "    print(f\"   ‚Ä¢ Cities with alerts: {', '.join(alert_cities)}\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS:\")\n",
    "print(f\"   ‚Ä¢ Run Streamlit app: streamlit run app.py\")\n",
    "print(f\"   ‚Ä¢ View interactive dashboard with forecasts\")\n",
    "print(f\"   ‚Ä¢ Monitor air quality alerts for Pakistani cities\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}